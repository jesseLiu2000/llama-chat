<DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="description" content="None">
        
        
        <link rel="shortcut icon" href="img/favicon.ico">
        <title>Fiber</title>
        <link href="css/bootstrap.min.css" rel="stylesheet">
        <link href="css/font-awesome.min.css" rel="stylesheet">
        <link href="css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/docco.min.css">

        <script src="js/jquery-1.10.2.min.js" defer></script>
        <script src="js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>
        <style>
          img {
            display: block;
            margin-left: auto;
            margin-right: auto;
          }
        </style>
    </head>

    <body class="homepage">
        <!-- <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="https://nlp.wustl.edu/">Fiber</a> -->

                <!-- Expanded navigation -->
                <!-- <div id="navbar-collapse" class="navbar-collapse collapse">

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item"> -->
<!--                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">-->
<!--                                <i class="fa fa-search"></i> Search-->
<!--                            </a>-->
                        <!-- </li>
                    </ul>
                </div>
            </div>
        </div> -->

        <div class="container">
            <div class="row">
                    <!-- <div class="col-md-2"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary"> -->
    <!-- <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div> -->

    
    <!-- <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#welcome" class="nav-link"></a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#overview" class="nav-link">Overview</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#method" class="nav-link">Method</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#result" class="nav-link">Results</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            </li> -->
            <!-- <li class="nav-item" data-level="2"><a href="#case-study" class="nav-link">Case Study</a>
              <ul class="nav flex-column">
              </ul>
            </li> -->
            <!-- <li class="nav-item" data-level="2"><a href="#demo" class="nav-link">Interactive Demo</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#release" class="nav-link">Release</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#discussion" class="nav-link">Further Discussion</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#future-work" class="nav-link">Future Direction</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#limitations" class="nav-link">Limitations</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#license" class="nav-link">License</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#team" class="nav-link">Team</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#acknowledgments" class="nav-link">Acknowledgments</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#citations" class="nav-link">Citations</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div> -->
<!-- </div> -->
</div>
                    <div class="col-md-9" role="main">


<h2 id="welcome", style="position: center;">Fiber: A Few Instructions Make Better Large Language Models</h2>
<p><br>
Authors: Nick Crispino<sup>*</sup>, <a href="https://jesseliu2000.github.io/">Zijie Liu</a><sup>*</sup>, <a href="https://kylemontgomery1.github.io/">Kyle Montgomery</a><sup>*</sup>, <a href="http://www.linkedin.com/in/yidan-tang">Yidan Tang</a><sup>*</sup>, <a href="https://zengfankun.com/">Fankun Zeng</a><sup>*</sup>
<br><br>
Updated: 4-12-2023<br><br>

<img src="logo.png" alt="Fiber" height="175">
<p style="text-align:center; font-size:.75em">Made in Midjourney</p>

We introduce Fiber, an effective instruction engineering technique for large language models. Fiber shows that careful use of the data can improve the performance of pretrained language models, such as LLaMA, to be competitive with ChatGPT on a wide set of NLP benchmarks for zero training cost.
<br></p>
<p><a href="http://fiber-llms.app/">Demo</a> &nbsp &nbsp <a href="https://github.com/wang-research-lab/fiber">Github</a></p>
<h3 id="overview">Overview</h3>
<p>Large language models (LLMs) such as ChatGPT and GPT-4 have revolutionized the ways in which machines understand and generate human language, allowing for more accurate completion of sophisticated natural language processing (NLP) tasks such as machine translation, text summarization, and sentiment analysis. In fact, LLMs in zero/few-shot settings are often able to beat existing models with benchmark-specific training.<br><br>
The general consensus in AI research is that an LLM’s performance follows scaling laws. Though recent advances have made it possible to train LLMs with hundreds of billions of parameters, this approach still requires significant computational resources, a long training time, and immense amounts of data. As such, API access can be prohibitively expensive if consistently used.<br><br>
In addition to the monetary concerns, the centralized nature of AI research obscures details of model architecture and training data. As such, recent progress has been met with backlash, with prominent industry tech leaders and researchers signing an open letter encouraging AI research labs to halt further development and the Center for AI and Digital Polity (CAIDP) filing a complaint with the Federal Trade Commission (FTC) regarding OpenAI’s release of GPT-4.
</p>
<h3 id="method">Method</h3>
<p>We introduce Fiber, an instruction engineering strategy that enables standard LLMs to mimic instruction-following LLMs across a set of challenging NLP tasks without any additional training.<br><br>
<img src="prompting.png" alt="Prompting Diagram"><br>
Fiber is an instruction-following LLM developed by combining LLaMA (65B) with instruction engineering. Our work aligns with recent work (<a href="https://crfm.stanford.edu/2023/03/13/alpaca.html">Alpaca</a>, <a href="https://bair.berkeley.edu/blog/2023/04/03/koala/">Koala</a>, <a href="https://vicuna.lmsys.org/">Vicuna</a>, <a href="https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html">Dolly</a>, <a href="https://arxiv.org/abs/2212.10560">Self-Instruct</a>), but our approach requires no additional costly training. <br>
<img src="cost.png" alt="Cost Diagram" width="60%"><br>
Furthermore, LLaMA, on which Fiber is based, is open-source and decentralized. Fully published details about the model's architecture and the training process are available, enabling users to have full control over their data when running locally. Often, this is cheaper compared to sending it off to a third-party through an API.
</p>
<h3 id="result">Results</h3>
<p>The following table shows our results across a handful of standard benchmarks. Unless otherwise indicated, all results use at most five-shots.</p>
<div style="overflow-x:auto;">
<table>
<thead>
<tr>
<th>Scenario/Model</th>
<th>Average Score</th>
<!-- <th>MMLU - EM</th> -->
<!-- <th>BoolQ - EM</th> -->
<!-- <th>NarrativeQA - F1</th> -->
<th>NaturalQuestions (closed-book) - F1</th>
<th>NaturalQuestions (open-book) - F1</th>
<th>QuAC - F1</th>
<th>HellaSwag - EM</th>
<!-- <th>OpenbookQA - EM</th> -->
<!-- <th>TruthfulQA - EM</th> -->
<!-- <th>MS MARCO (regular) - RR@10</th>
<th>MS MARCO (TREC) - NDCG@10</th> -->
<!-- <th>CNN/DailyMail - ROUGE-2</th> -->
<!-- <th>XSUM - ROUGE-2</th> -->
<th>IMDB - EM</th>
<th>CivilComments - EM</th>
<!-- <th>RAFT - EM</th> -->
<!-- <th>DROP - F1</th>
<th>ARC-Challenge - EM</th>
<th>ARC-Easy - EM</th>
<th>Winogrande - EM</th> -->
<th>Bar (MBE) - EM</th>
<!-- <th>LSAT - Acc</th>
<th>GRE Verbal - Acc</th>
<th>GRE Quant - Acc</th> -->
</tr>
</thead>
<tbody>
<tr>
  <td><strong>Fiber (ours)</strong>
  </td>
  <td>0.612</td>
  <!-- <td>0.529</td> -->
  <!-- <td>0.870</td> -->
  <!-- <td><strong>0.765</strong></td> -->
  <td><strong>0.427</strong></td>
  <td><strong>0.685</strong></td>
  <td>0.398</td>
  <td>0.691</td>
  <!-- <td>0.762</td>
  <td>0.561</td> -->
  <!-- <td>-</td>
  <td>-</td> -->
  <!-- <td>0.169</td> -->
  <!-- <td><strong>0.183</strong></td> -->
  <td><strong>0.942</strong></td>
  <td>0.644</td>
  <!-- <td>0.702</td> -->
  <!-- <td>0.522</td>
  <td>0.764</td>
  <td>0.874</td>
  <td>0.642</td> -->
  <td>0.495</td>
  <!-- <td>-</td>
  <td>-</td>
  <td>-</td> -->
</tr>
<tr>
  <td>ChatGPT</td>
  <td>0.637</td>
  <!-- <td><strong>0.595</strong></td> -->
  <!-- <td>0.811</td> -->
  <!-- <td>0.665</td> -->
  <td>0.389</td>
  <td>0.628</td>
  <td><strong>0.512</strong></td>
  <td><strong>0.841</strong></td>
  <!-- <td><strong>0.832</strong></td>
  <td><strong>0.627</strong></td> -->
  <!-- <td>0.266</td>
  <td>0.512</td> -->
  <!-- <td><strong>0.171</strong></td> -->
  <!-- <td>0.143</td> -->
  <td>0.857</td>
  <td><strong>0.670</strong></td>
  <!-- <td>0.757</td> -->
  <!-- <td><strong>0.546</strong></td>
  <td><strong>0.846</strong></td>
  <td><strong>0.921</strong></td>
  <td><strong>0.712</strong></td> -->
  <td><strong>0.560</strong></td>
  <!-- <td>0.592<sup>3</sup></td>
<td>0.54<sup>3</sup></td>
<td>0.36<sup>3</sup></td>   -->
</tr>
<!-- <tr>
  <td>LLaMA (65B)
  </td>
  <td>0.552</td> -->
  <!-- <td>-</td>
  <td>0.803</td> -->
  <!-- <td>0.482</td> -->
  <!-- <td>0.442</td>
  <td>0.665</td>
  <td>0.405</td>
  <td>0.629</td> -->
  <!-- <td>0.774</td> -->
  <!-- <td>-</td> -->
  <!-- <td>-</td>
  <td>-</td> -->
  <!-- <td>0.0179</td> -->
  <!-- <td>-</td> -->
  <!-- <td>0.641</td>
  <td>0.631</td> -->
  <!-- <td>-</td> -->
  <!-- <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td> -->
  <!-- <td>0.450</td> -->
  <!-- <td>-</td>
  <td>-</td>
  <td>-</td> -->
<!-- </tr> -->
<!-- <tr>
  <td>GPT-J (6B)</td>
  <td>0.249</td>
  <td>0.649</td>
  <td>0.545</td>
  <td>0.156</td>
  <td>0.559</td>
  <td>0.33</td>
  <td>0.663</td>
  <td>0.514</td>
  <td>0.199</td>
  <td>0.152</td>
  <td>0.345</td>
  <td>0.131</td>
  <td>0.096</td>
  <td>0.939</td>
  <td>0.52</td>
  <td>0.619</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
</tr> -->
<!-- <tr>
  <td>GPT-4</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
</tr>
<tr>
  <td>GPT-4<sup>4</sup></td>
  <td>0.864</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>0.953<sup>5</sup></td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>0.809<sup>6</sup></td>
  <td>0.963<sup>7</sup></td>
  <td>-</td>
  <td>0.875</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
</tr> -->
<!-- <tr>
  <td>text-davinci-003</td>
  <td>0.569</td>
  <td><strong>0.881</strong></td>
  <td>0.727</td>
  <td>0.406</td>
  <td><strong>0.77</strong></td>
  <td><strong>0.525</strong></td>
  <td>0.822</td>
  <td>0.646</td>
  <td>0.593</td>
  <td>0.368</td>
  <td>0.644</td>
  <td>0.156</td>
  <td>0.124</td>
  <td>0.848</td>
  <td><strong>0.684</strong></td>
  <td><strong>0.759</strong></td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td>
  <td>-</td> -->
  <!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr> -->
<!-- <tr>
<td>Cohere Command beta (52.4B)</td>
<td>0.452</td>
<td>0.856</td>
<td>0.752</td>
<td>0.372</td>
<td>0.76</td>
<td>0.432</td>
<td>0.811</td>
<td>0.582</td>
<td>0.269</td>
<td><strong>0.472</strong></td>
<td><strong>0.762</strong></td>
<td>0.161</td>
<td>0.152</td>
<td>0.96</td>
<td>0.601</td>
<td>0.667</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr> -->
<!-- <tr>
<td>text-davinci-002</td>
<td>0.568</td>
<td>0.877</td>
<td>0.727</td>
<td>0.383</td>
<td>0.713</td>
<td>0.445</td>
<td>0.815</td>
<td>0.594</td>
<td>0.61</td>
<td>0.421</td>
<td>0.664</td>
<td>0.153</td>
<td>0.144</td>
<td>0.948</td>
<td>0.668</td>
<td>0.733</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr> -->
<!-- <tr>
<td>TNLG v2 (530B)</td>
<td>0.469</td>
<td>0.809</td>
<td>0.722</td>
<td>0.384</td>
<td>0.642</td>
<td>0.39</td>
<td>0.799</td>
<td>0.562</td>
<td>0.251</td>
<td>0.377</td>
<td>0.643</td>
<td>0.161</td>
<td>0.169</td>
<td>0.941</td>
<td>0.601</td>
<td>0.679</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr>
<tr>
<td>Anthropic-LM v4-s3 (52B)</td>
<td>0.481</td>
<td>0.815</td>
<td>0.728</td>
<td>0.288</td>
<td>0.686</td>
<td>0.431</td>
<td>0.807</td>
<td>0.558</td>
<td>0.368</td>
<td>-</td>
<td>-</td>
<td>0.154</td>
<td>0.134</td>
<td>0.934</td>
<td>0.61</td>
<td>0.699</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr>
<tr>
<td>J1-Grande v2 beta (17B)</td>
<td>0.445</td>
<td>0.812</td>
<td>0.725</td>
<td>0.337</td>
<td>0.625</td>
<td>0.392</td>
<td>0.764</td>
<td>0.56</td>
<td>0.306</td>
<td>0.285</td>
<td>0.46</td>
<td>0.146</td>
<td>0.152</td>
<td>0.957</td>
<td>0.546</td>
<td>0.679</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr>
<tr>
<td>Luminous Supreme (70B)</td>
<td>0.38</td>
<td>0.775</td>
<td>0.711</td>
<td>0.293</td>
<td>0.649</td>
<td>0.37</td>
<td>-</td>
<td>-</td>
<td>0.222</td>
<td>-</td>
<td>-</td>
<td>0.15</td>
<td>0.136</td>
<td>0.959</td>
<td>0.562</td>
<td>0.653</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr> -->
<!-- <tr>
<td>Cohere Command beta (6.1B)</td>
<td>0.406</td>
<td>0.798</td>
<td>0.709</td>
<td>0.229</td>
<td>0.717</td>
<td>0.375</td>
<td>0.752</td>
<td>0.55</td>
<td>0.203</td>
<td>0.434</td>
<td>0.709</td>
<td>0.153</td>
<td>0.122</td>
<td><strong>0.961</strong></td>
<td>0.54</td>
<td>0.634</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr>
<tr>
<td>Cohere xlarge v20221108 (52.4B)</td>
<td>0.382</td>
<td>0.762</td>
<td>0.672</td>
<td>0.361</td>
<td>0.628</td>
<td>0.374</td>
<td>0.81</td>
<td>0.588</td>
<td>0.169</td>
<td>0.315</td>
<td>0.55</td>
<td>0.153</td>
<td>0.153</td>
<td>0.956</td>
<td>0.524</td>
<td>0.624</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr>
<tr>
<td>OPT (175B)</td>
<td>0.318</td>
<td>0.793</td>
<td>0.671</td>
<td>0.297</td>
<td>0.615</td>
<td>0.36</td>
<td>0.791</td>
<td>0.586</td>
<td>0.25</td>
<td>0.288</td>
<td>0.448</td>
<td>0.146</td>
<td>0.155</td>
<td>0.947</td>
<td>0.505</td>
<td>0.606</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr> -->
<!-- <tr>
<td>Cohere xlarge v20220609 (52.4B)</td>
<td>0.353</td>
<td>0.718</td>
<td>0.65</td>
<td>0.312</td>
<td>0.595</td>
<td>0.361</td>
<td>0.811</td>
<td>0.55</td>
<td>0.198</td>
<td>0.273</td>
<td>0.459</td>
<td>0.144</td>
<td>0.129</td>
<td>0.956</td>
<td>0.532</td>
<td>0.633</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr>
<tr>
<td>davinci (175B)</td>
<td>0.422</td>
<td>0.722</td>
<td>0.687</td>
<td>0.329</td>
<td>0.625</td>
<td>0.36</td>
<td>0.775</td>
<td>0.586</td>
<td>0.194</td>
<td>0.211</td>
<td>0.378</td>
<td>0.127</td>
<td>0.126</td>
<td>0.933</td>
<td>0.532</td>
<td>0.642</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr> -->
<!-- <tr>
<td>GLM (130B)</td>
<td>0.344</td>
<td>0.784</td>
<td>0.706</td>
<td>0.148</td>
<td>0.642</td>
<td>0.272</td>
<td>-</td>
<td>-</td>
<td>0.218</td>
<td>-</td>
<td>-</td>
<td>0.154</td>
<td>0.132</td>
<td>0.955</td>
<td>0.5</td>
<td>0.598</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr>
<tr>
<td>J1-Jumbo v1 (178B)</td>
<td>0.259</td>
<td>0.776</td>
<td>0.695</td>
<td>0.293</td>
<td>0.595</td>
<td>0.358</td>
<td>0.765</td>
<td>0.534</td>
<td>0.175</td>
<td>0.21</td>
<td>0.363</td>
<td>0.144</td>
<td>0.129</td>
<td>0.943</td>
<td>0.553</td>
<td>0.681</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr> -->
<!-- <tr>
<td>Luminous Extended (30B)</td>
<td>0.321</td>
<td>0.767</td>
<td>0.665</td>
<td>0.254</td>
<td>0.609</td>
<td>0.349</td>
<td>-</td>
<td>-</td>
<td>0.221</td>
<td>-</td>
<td>-</td>
<td>0.139</td>
<td>0.124</td>
<td>0.947</td>
<td>0.524</td>
<td>0.523</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr> -->
<!-- <tr>
<td>BLOOM (176B)</td>
<td>0.299</td>
<td>0.704</td>
<td>0.662</td>
<td>0.216</td>
<td>0.621</td>
<td>0.361</td>
<td>0.744</td>
<td>0.534</td>
<td>0.205</td>
<td>0.236</td>
<td>0.386</td>
<td>0.08</td>
<td>0.03</td>
<td>0.945</td>
<td>0.62</td>
<td>0.592</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr> -->
<!-- <tr>
<td>OPT (66B)</td>
<td>0.276</td>
<td>0.76</td>
<td>0.638</td>
<td>0.258</td>
<td>0.596</td>
<td>0.357</td>
<td>0.745</td>
<td>0.534</td>
<td>0.201</td>
<td>0.237</td>
<td>0.482</td>
<td>0.136</td>
<td>0.126</td>
<td>0.917</td>
<td>0.506</td>
<td>0.557</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr> -->
<!-- <tr>
<td>J1-Grande v1 (17B)</td>
<td>0.27</td>
<td>0.722</td>
<td>0.672</td>
<td>0.233</td>
<td>0.578</td>
<td>0.362</td>
<td>0.739</td>
<td>0.52</td>
<td>0.193</td>
<td>0.161</td>
<td>0.341</td>
<td>0.143</td>
<td>0.122</td>
<td>0.953</td>
<td>0.529</td>
<td>0.658</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr> -->
<!-- <tr>
<td>Cohere large v20220720 (13.1B)</td>
<td>0.324</td>
<td>0.725</td>
<td>0.625</td>
<td>0.232</td>
<td>0.573</td>
<td>0.338</td>
<td>0.736</td>
<td>0.542</td>
<td>0.181</td>
<td>0.19</td>
<td>0.33</td>
<td>0.126</td>
<td>0.108</td>
<td>0.933</td>
<td>0.507</td>
<td>0.596</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr> -->
<!-- <tr>
<td>text-curie-001</td>
<td>0.237</td>
<td>0.62</td>
<td>0.582</td>
<td>0.175</td>
<td>0.571</td>
<td>0.358</td>
<td>0.676</td>
<td>0.514</td>
<td>0.257</td>
<td>0.271</td>
<td>0.507</td>
<td>0.152</td>
<td>0.076</td>
<td>0.923</td>
<td>0.537</td>
<td>0.489</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr>
<tr>
<td>GPT-NeoX (20B)</td>
<td>0.276</td>
<td>0.683</td>
<td>0.599</td>
<td>0.193</td>
<td>0.596</td>
<td>0.326</td>
<td>0.718</td>
<td>0.524</td>
<td>0.216</td>
<td>0.184</td>
<td>0.398</td>
<td>0.123</td>
<td>0.102</td>
<td>0.948</td>
<td>0.516</td>
<td>0.505</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr>
<tr>
<td>Luminous Base (13B)</td>
<td>0.27</td>
<td>0.719</td>
<td>0.605</td>
<td>0.202</td>
<td>0.568</td>
<td>0.334</td>
<td>-</td>
<td>-</td>
<td>0.182</td>
<td>-</td>
<td>-</td>
<td>0.11</td>
<td>0.105</td>
<td>0.939</td>
<td>0.544</td>
<td>0.473</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr>
<tr>
<td>Cohere medium v20221108 (6.1B)</td>
<td>0.254</td>
<td>0.7</td>
<td>0.61</td>
<td>0.199</td>
<td>0.517</td>
<td>0.314</td>
<td>0.726</td>
<td>0.538</td>
<td>0.215</td>
<td>0.175</td>
<td>0.373</td>
<td>0.121</td>
<td>0.099</td>
<td>0.935</td>
<td>0.5</td>
<td>0.591</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr>
<tr>
<td>TNLG v2 (6.7B)</td>
<td>0.242</td>
<td>0.698</td>
<td>0.631</td>
<td>0.21</td>
<td>0.561</td>
<td>0.345</td>
<td>0.704</td>
<td>0.478</td>
<td>0.167</td>
<td>0.158</td>
<td>0.332</td>
<td>0.146</td>
<td>0.11</td>
<td>0.927</td>
<td>0.532</td>
<td>0.525</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr>
<tr>
<td>J1-Large v1 (7.5B)</td>
<td>0.241</td>
<td>0.683</td>
<td>0.623</td>
<td>0.19</td>
<td>0.532</td>
<td>0.328</td>
<td>0.7</td>
<td>0.514</td>
<td>0.197</td>
<td>0.147</td>
<td>0.292</td>
<td>0.134</td>
<td>0.102</td>
<td>0.956</td>
<td>0.532</td>
<td>0.545</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr>
<tr>
<td>curie (6.7B)</td>
<td>0.243</td>
<td>0.656</td>
<td>0.604</td>
<td>0.199</td>
<td>0.552</td>
<td>0.321</td>
<td>0.682</td>
<td>0.502</td>
<td>0.232</td>
<td>0.162</td>
<td>0.3</td>
<td>0.113</td>
<td>0.091</td>
<td>0.889</td>
<td>0.539</td>
<td>0.49</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr>
<tr>
<td>Cohere medium v20220720 (6.1B)</td>
<td>0.279</td>
<td>0.659</td>
<td>0.559</td>
<td>0.177</td>
<td>0.504</td>
<td>0.279</td>
<td>0.706</td>
<td>0.496</td>
<td>0.19</td>
<td>0.152</td>
<td>0.374</td>
<td>0.077</td>
<td>0.087</td>
<td>0.935</td>
<td>0.504</td>
<td>0.52</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr>
<tr>
<td>text-babbage-001</td>
<td>0.229</td>
<td>0.451</td>
<td>0.429</td>
<td>0.07</td>
<td>0.33</td>
<td>0.284</td>
<td>0.561</td>
<td>0.452</td>
<td>0.233</td>
<td>0.208</td>
<td>0.449</td>
<td>0.151</td>
<td>0.046</td>
<td>0.913</td>
<td>0.499</td>
<td>0.509</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr>
<tr>
<td>T0pp (11B)</td>
<td>0.407</td>
<td>0</td>
<td>0.151</td>
<td>0.039</td>
<td>0.19</td>
<td>0.121</td>
<td>-</td>
<td>-</td>
<td>0.377</td>
<td>-</td>
<td>-</td>
<td>0.122</td>
<td>0.09</td>
<td>0.207</td>
<td>0.234</td>
<td>0.118</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr>
<tr>
<td>UL2 (20B)</td>
<td>0.291</td>
<td>0.746</td>
<td>0.083</td>
<td>0.204</td>
<td>0.349</td>
<td>0.144</td>
<td>-</td>
<td>-</td>
<td>0.193</td>
<td>-</td>
<td>-</td>
<td>0.03</td>
<td>0.058</td>
<td>0.337</td>
<td>0.521</td>
<td>0.404</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr>
<tr>
<td>T5 (11B)</td>
<td>0.29</td>
<td>0.761</td>
<td>0.086</td>
<td>0.194</td>
<td>0.477</td>
<td>0.116</td>
<td>-</td>
<td>-</td>
<td>0.133</td>
<td>-</td>
<td>-</td>
<td>0.043</td>
<td>0.015</td>
<td>0.379</td>
<td>0.509</td>
<td>0.37</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr>
<tr>
<td>Cohere small v20220720 (410M)</td>
<td>0.264</td>
<td>0.457</td>
<td>0.294</td>
<td>0.078</td>
<td>0.309</td>
<td>0.219</td>
<td>0.483</td>
<td>0.348</td>
<td>0.217</td>
<td>-</td>
<td>0.304</td>
<td>0.063</td>
<td>0.033</td>
<td>0.578</td>
<td>0.501</td>
<td>0.492</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr>
<tr>
<td>ada (350M)</td>
<td>0.243</td>
<td>0.581</td>
<td>0.326</td>
<td>0.082</td>
<td>0.365</td>
<td>0.242</td>
<td>0.435</td>
<td>0.38</td>
<td>0.215</td>
<td>0.102</td>
<td>0.29</td>
<td>0.09</td>
<td>0.022</td>
<td>0.849</td>
<td>0.517</td>
<td>0.423</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr>
<tr>
<td>babbage (1.3B)</td>
<td>0.235</td>
<td>0.574</td>
<td>0.491</td>
<td>0.119</td>
<td>0.451</td>
<td>0.273</td>
<td>0.555</td>
<td>0.438</td>
<td>0.188</td>
<td>0.122</td>
<td>0.317</td>
<td>0.079</td>
<td>0.045</td>
<td>0.597</td>
<td>0.519</td>
<td>0.455</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr>
<tr>
<td>text-ada-001</td>
<td>0.238</td>
<td>0.464</td>
<td>0.238</td>
<td>0.025</td>
<td>0.149</td>
<td>0.176</td>
<td>0.429</td>
<td>0.346</td>
<td>0.232</td>
<td>0.134</td>
<td>0.302</td>
<td>0.136</td>
<td>0.034</td>
<td>0.822</td>
<td>0.503</td>
<td>0.406</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr>
<tr>
<td>YaLM (100B)</td>
<td>0.243</td>
<td>0.634</td>
<td>0.252</td>
<td>0.068</td>
<td>0.227</td>
<td>0.162</td>
<td>-</td>
<td>-</td>
<td>0.202</td>
<td>-</td>
<td>-</td>
<td>0.017</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td> -->
<!-- <td>-</td>
<td>-</td>
<td>-</td> -->
<!-- </tr> -->
</tbody>
</table>
    </div>
<p style="font-size:.75em">For all results, the higher the better.</p>

<br><p>We put Fiber through a comprehensive evaluation on 6 core scenarios outlined in Holistic Evaluation of Language Models (<a href="https://crfm.stanford.edu/helm/latest/">HELM</a>) and the multiple-choice section of the Uniform Bar Examination. For the sake of comparison, we put ChatGPT through the same rigorous evaluation. Our initial results suggest that Fiber is competitive with ChatGPT, with Fiber scoring just 0.025 below ChatGPT on average.</p>

<!-- </p>

<h3 id="case-study">Case Study</h3>

<p>TODO
</p> -->

<h3 id="demo">Interactive Demo</h3>

<p>
Our <a href="http://fiber-llms.app/">interactive demo</a> allows you to chat with Fiber.<br>
</p>

<!-- Display the demo video -->
<!-- <div>
  <a style="display: flex; justify-content: center;">
    <video autoplay muted loop src="video.mp4" type="video/mp4" style="width: 80%;" id="demo"></video>
  </a>
</div> -->

<h3 id="release">Release</h3>
<p>
So far, we have released:
<ul>
  <li><a href="https://nlp.wustl.edu/fiber">This blog</a></li>
  <li><a href="http://fiber-llms.app/">An interactive demo</a></li>
</ul>
In the coming weeks, we aim to publish a full report detailing the instruction engineering technique behind Fiber, as well as our evaluation methodology. We also plan to open-source all of our code, in hopes that more academic research can be done regarding data-centric strategies to increase the reliability of AI systems.<br><br>
At the same time, we recognize the heightened risk surrounding this release, as any release that increases the performance of AI systems carries some inherent danger, especially given that our approach requires no additional training to implement. However, we believe that the benefit of our research to the academic community outweighs the
potential costs.<br><br>
Furthermore, we understand the potential drawbacks of releasing an interactive demo, namely concerns regarding producing disinformation and harmful content. We are exploring further methods to mitigate these risks.
</p>

<h3 id="discussion">Further Discussion</h3>
<ul>
  <li>
Data-Centric AI: We hope that our work is impactful in the ongoing debate between model-centric AI and data-centric AI. Though scaling to larger models certainly enables more sophisticated NLP tasks to be accomplished, our work suggests that it’s equally effective to modify existing weaker AI models using innovative instruction engineering techniques. Other recent publications (Alpaca, Koala, Vicuna, Dolly, Self-Instruct) suggest that it’s also effective to train small models on high-quality instruction-following data. Both approaches avoid the risk and cost of training new, innately more powerful
language models.
  </li>
  <li>
Decentralization: Given concerns about centralized LLMs regarding data privacy, it's important for open-source alternatives to exist that achieve comparable performance. Additionally, open-source alternatives offer details about model architecture and training data.
  </li>
</ul>

<h3 id="future-work">Future Direction</h3>
<ul>
<li>Reproducibility: We plan to evaluate Fiber on more benchmark datasets beyond those listed above. We'll start with the remaining HELM scenarios, then evaluate on other exams, and finally, on the remaining tasks ChatGPT was evaluated on <a href="https://arxiv.org/pdf/2302.06476.pdf">here</a>.</li>
<li>Safety: We must explore methods to mitigate the risks associated with using LLMs in conjunction with Fiber, namely
misinformation, bias, and harmful content. </li>
<li>Evaluation: We will measure our performance on benchmark datasets using a selection of additional metrics targeting robustness, fairness, bias, and misinformation, rather than using just accuracy.
</li>
<li>Understanding: In addition to formalizing our method, additional work related to understanding the mechanisms behind why Fiber is successful is needed. Specifically, we want to know if Fiber applies to other LLMs and if we can make our instruction engineering more efficient.</li>
</ul>


<h3 id="limitations">Limitations</h3>

<p>
Although recent advances for LLMs have resulted in the completion of more sophisticated NLP tasks, the issue of alignment with societal values remains open. LLMs are still prone to produce harmful content, biased responses, and misinformation. Our initial results suggest that it’s possible to reduce these risks not by training larger, complex LLMs, but rather by leveraging instruction engineering. However, more research into this subject is needed.<br><br>
Additionally, because LLaMA’s context window is half that of ChatGPT, we are regularly forced to cut out shots on some datasets. We would expect that a larger context length could improve our results and we hope that more open LLMs with large context lengths are released soon.
</p>

<h3 id="license">License</h3>

<p>The online demo serves as a research preview intended for non-commercial use only. Its usage is subject to the model <a href="https://github.com/facebookresearch/llama/blob/main/MODEL_CARD.md">License</a> of LLaMA. Please contact us if you find any potential violations.
</p>  

<h3 id="team">Team</h3>
Fiber was developed as a joint effort between WashU,  Berkeley, and Stanford.<br><br>
Students (alphabetical order): Nick Crispino, Zijie Liu, Kyle Montgomery, Yidan Tang, Fankun Zeng<br><br>
Advisors (alphabetical order):<br><br>

<h3 id="acknowledgments">Acknowledgments</h3>
<p>Our work on this project greatly depends on previous work surrounding large language models. Specifically, we would like to thank our collaborators at Berkeley's BAIR, as well as our collaborators at Stanford for sharing their work on HELM; our evaluation methodology heavily depends on and closely follows their work. A special thanks goes out to our colleague Kripa George for help with logo and diagram design, as well as Midjourney. Furthermore, this project would not have been possible had Meta not provided us with research access to the weights of LLaMA. Finally, we extend our gratitude to OpenAI for API access to ChatGPT and GPT-4; it has been integral in the successful completion of this work.
</p>

<h3 id="citations">Citation</h3>
<pre><code>@misc{fiber,
author = {Nick Crispino, Zijie Liu, Kyle Montgomery, Yidan Tang, Fankun Zeng},
title = {Fiber: A Few Instructions Make Better Large Language Models},
howpublished = {Blog post},
month = {April},
year = {2023},
url = {https://nlp.wustl.edu/fiber/},
urldate = {2023-04-12}
}
</code></pre>


                    </div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p></p>
        </footer>
        <script>
            var base_url = ".",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="js/base.js" defer></script>
        <script src="search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>

<!--
MkDocs version : 1.4.2
Build Date UTC : 2023-03-29 05:26:59.687095+00:00
-->
